import sys
import os
import shutil
import logging
import json
import re
from pathlib import Path
from typing import List, Dict, Optional
from uuid import uuid4
from concurrent.futures import ThreadPoolExecutor, as_completed

from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

# Add project root to sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from main import VietnameseEmbedder, FAISSVectorStore, get_rag_agent  # noqa: E402
from agents import get_mcp_planner_agent, AnswerGeneratorAgent  # noqa: E402
from utils import process_pdf  # noqa: E402
from persistent_memory import PersistentMemory  # noqa: E402
from mcp_client.client import MCPClient  # noqa: E402

# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI()

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Paths
BASE_DIR = Path(__file__).resolve().parent.parent
PDF_DIR = BASE_DIR / "data" / "pdfs"
os.makedirs(PDF_DIR, exist_ok=True)

# Globals
memory = PersistentMemory(db_path=str(BASE_DIR / "data" / "memory.db"), max_history=25)
embedder: Optional[VietnameseEmbedder] = None
vector_stores: Dict[str, FAISSVectorStore] = {}
file_meta: Dict[str, str] = {}  # file_id -> original filename
last_file_id: Optional[str] = None
rag_agent = None
mcp_client = MCPClient()
answer_agent = AnswerGeneratorAgent(get_rag_agent())


class QueryRequest(BaseModel):
    query: str
    allow_web_search: bool = False
    session_id: str = "user_session_1"


class HistoryItem(BaseModel):
    query: str
    response: str
    timestamp: str


class CompareRequest(BaseModel):
    file_ids: List[str]
    query: str


class SessionRequest(BaseModel):
    session_id: str


@app.post("/upload_pdf")
async def upload_pdf(file: UploadFile = File(...)):
    """
    Upload một file PDF, lưu với file_id riêng và tạo FAISS vector store cho file đó.
    """
    global embedder, last_file_id
    if not file.filename.endswith(".pdf"):
        raise HTTPException(status_code=400, detail="File phải là PDF")

    try:
        original_name = Path(file.filename).name or "uploaded.pdf"
        stem = Path(original_name).stem
        ext = Path(original_name).suffix or ".pdf"
        file_id = f"{stem}_{uuid4().hex[:8]}{ext}"
        dest_path = PDF_DIR / file_id

        with open(dest_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)

        documents = process_pdf(str(dest_path))
        logger.info("Đã xử lý PDF %s, tạo %s chunks", file_id, len(documents))

        if embedder is None:
            embedder = VietnameseEmbedder()
        store = FAISSVectorStore(documents, embedder)
        vector_stores[file_id] = store
        file_meta[file_id] = original_name
        last_file_id = file_id

    return {"message": "PDF đã được xử lý thành công", "file_id": file_id, "file_name": original_name}
    except Exception as e:
        logger.error("Lỗi khi xử lý PDF: %s", e)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/files")
async def list_files():
    """
    Liệt kê các file PDF đã upload (trong phiên chạy hiện tại).
    """
    return [{"file_id": fid, "file_name": file_meta.get(fid, fid)} for fid in vector_stores.keys()]


@app.post("/upload_pdfs")
async def upload_multiple_pdfs(files: List[UploadFile] = File(...)):
    """
    Upload nhiều PDF cùng lúc, xử lý song song và trả danh sách file_id.
    """
    global embedder, last_file_id
    if not files:
        raise HTTPException(status_code=400, detail="Chưa chọn file PDF")

    if embedder is None:
        embedder = VietnameseEmbedder()

    results = []
    errors = []

    def handle_one(upload_file: UploadFile):
        original_name = Path(upload_file.filename).name or "uploaded.pdf"
        stem = Path(original_name).stem
        ext = Path(original_name).suffix or ".pdf"
        file_id_local = f"{stem}_{uuid4().hex[:8]}{ext}"
        dest_path = PDF_DIR / file_id_local
        with open(dest_path, "wb") as buffer:
            shutil.copyfileobj(upload_file.file, buffer)
        docs = process_pdf(str(dest_path))
        store_local = FAISSVectorStore(docs, embedder)
        return file_id_local, original_name, store_local

    with ThreadPoolExecutor(max_workers=min(len(files), 4)) as executor:
        future_map = {executor.submit(handle_one, f): f.filename for f in files if f.filename.endswith(".pdf")}
        for fut in as_completed(future_map):
            try:
                fid, fname, store = fut.result()
                vector_stores[fid] = store
                file_meta[fid] = fname
                last_file_id = fid
                results.append({"file_id": fid, "file_name": fname})
            except Exception as exc:
                errors.append(str(exc))

    if not results and errors:
        raise HTTPException(status_code=500, detail="; ".join(errors))

    return {"uploaded": results, "errors": errors}


@app.post("/compare_pdfs")
async def compare_pdfs(request: CompareRequest):
    """
    So sánh/tra cứu câu hỏi trên hai PDF đã upload.
    """
    if len(request.file_ids) < 2:
        raise HTTPException(status_code=400, detail="Cần cung cấp ít nhất 2 file_id để so sánh.")

    missing = [fid for fid in request.file_ids if fid not in vector_stores]
    if missing:
        raise HTTPException(status_code=400, detail=f"File_id không tồn tại: {', '.join(missing)}")

    selected_ids = request.file_ids[:2]
    contexts = []
    for fid in selected_ids:
        store = vector_stores[fid]
        docs = store.retrieve(request.query, top_k=3)
        if not docs:
            contexts.append(f"[{file_meta.get(fid, fid)}] Không tìm thấy nội dung phù hợp.")
            continue
        chunk_text = "\n\n".join([f"[Chunk {doc.metadata.get('index')}] {doc.page_content}" for doc in docs])
        contexts.append(f"[{file_meta.get(fid, fid)}]\n{chunk_text}")

    combined_context = "\n\n-----\n\n".join(contexts)
    answer = answer_agent.run(request.query, combined_context, "vector_store_compare", "")

    return {"answer": answer, "file_ids": selected_ids}


@app.post("/ask")
async def ask_question(request: QueryRequest):
    """
    Nhận câu hỏi, dùng planner (MCP tools) để lấy context, sau đó Gemini trả lời.
    Mọi lỗi planner/thiếu dữ liệu sẽ trả lời thân thiện thay vì 500.
    """
    query = request.query
    session_id = request.session_id or "user_session_1"

    try:
        planner_agent = get_mcp_planner_agent(allow_web_search=request.allow_web_search)
        planner_output = planner_agent.run(f"[SESSION:{session_id}] {query}").content

        try:
            match = re.search(r"{.*}", planner_output, re.DOTALL)
            payload = match.group(0) if match else planner_output
            obj = json.loads(payload)
            source = obj.get("source", "")
            context = obj.get("context", "")
            memory_context = obj.get("memory", "")
        except Exception:
            logger.warning("Planner output không parse được JSON: %s", planner_output)
            friendly = "Không đọc được kế hoạch, bạn có thể hỏi lại hoặc bật tìm kiếm web."
            return {"answer": friendly}

        if source == "error":
            logger.warning("Planner trả về error: %s", context)
            friendly = context or "Không lấy được kế hoạch. Thử lại hoặc bật tìm kiếm web."
            return {"answer": friendly}

        answer = answer_agent.run(query, context, source, memory_context)

        try:
            mcp_client.invoke(
                "memory_add",
                {
                    "session_id": session_id,
                    "query": query,
                    "answer": answer,
                    "chunk_index": None,
                },
            )
        except Exception as e:
            logger.warning("Lưu lịch sử lỗi (bỏ qua): %s", e)

        return {"answer": answer}
    except Exception as e:
        logger.error("Lỗi khi xử lý câu hỏi: %s", e)
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/history", response_model=List[HistoryItem])
async def get_history(session_id: str = "user_session_1", page: int = 1, per_page: int = 25):
    try:
        history_lines = mcp_client.invoke(
            "memory_get", {"session_id": session_id, "max_rows": per_page}
        )
        history_items = []
        for line in history_lines:
            try:
                timestamp_end = line.find("] Query: ")
                if timestamp_end == -1:
                    continue
                timestamp = line[1:timestamp_end]
                query_start = timestamp_end + len("] Query: ")
                query_end = line.find("\nResponse: ")
                if query_end == -1:
                    continue
                query_val = line[query_start:query_end]
                response_val = line[query_end + len("\nResponse: "):]
                history_items.append(HistoryItem(query=query_val, response=response_val, timestamp=timestamp))
            except Exception as e:
                logger.warning("Lỗi khi parse lịch sử: %s (line=%s)", e, line)
                continue
        return history_items
    except Exception as e:
        logger.error("Lỗi khi lấy lịch sử: %s", e)
        raise HTTPException(status_code=500, detail=str(e))


@app.delete("/session")
async def delete_session(req: SessionRequest):
    """
    Xóa toàn bộ lịch sử hội thoại của một session_id.
    """
    try:
        memory.clear_session(req.session_id)
        return {"message": f"Đã xóa lịch sử session {req.session_id}"}
    except Exception as e:
        logger.error("Lỗi khi xóa session: %s", e)
        raise HTTPException(status_code=500, detail=str(e))
